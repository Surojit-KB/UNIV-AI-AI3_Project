{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFj7oRxezlS8rxDQqOhqQS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Surojit-KB/UNIV-AI-AI3_Project/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ2WxVPn06oG"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dot\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, Embedding, Dense, TimeDistributed,LSTM, GRU,Dropout, Bidirectional, Conv1D, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kji07lM1QdY",
        "outputId": "4f72d588-ee1d-48c0-ba99-e40e4dcdf3dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sJeZUHIzc_"
      },
      "source": [
        "def get_dataframe(file):\n",
        "  f = open(file, 'r')\n",
        "  #loading json file \n",
        "  data = json.loads(f.read())\n",
        "  #creating empty lists to store df values \n",
        "  iid = []\n",
        "  tit = []\n",
        "  con = []\n",
        "  que = []\n",
        "  ans = []\n",
        "  txt = []\n",
        "  #root tags contains 'title' tag and 'paragraphs' list \n",
        "  for i in range(len(data['data'])):\n",
        "    title = data['data'][i]['title']\n",
        "    #'paragraphs' list contains 'context' tag and 'qas' list \n",
        "    for p in range(len(data['data'][i]['paragraphs'])):\n",
        "      context = data['data'][i]['paragraphs'][p]['context']\n",
        "      for q in range(len(data['data'][i]['paragraphs'][p]['qas'])):\n",
        "        # 'qas'list contains 'question', 'Id' tag and 'answers' list \n",
        "        question = data['data'][i]['paragraphs'][p]['qas'][q]['question']\n",
        "        id = data['data'][i]['paragraphs'][p]['qas'][q]['id']\n",
        "        #'answers' list contains 'answer_start' and 'text' tag \n",
        "        for a in range(len(data['data'][i]['paragraphs'][p]['qas'][q]['answers'])):\n",
        "          ans_start = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['answer_start']\n",
        "          text = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['text']\n",
        "          \n",
        "          #appending values to list \n",
        "          iid.append(id)\n",
        "          tit.append(title)\n",
        "          con.append(context)\n",
        "          que.append(question)\n",
        "          ans.append(ans_start)\n",
        "          txt.append(text)\n",
        "  #creating dataframe from lists \n",
        "  new_df = pd.DataFrame(columns=['Id', 'title', 'context', 'question', 'ans_start', 'text'])\n",
        "  new_df.Id = iid\n",
        "  new_df.title=tit\n",
        "  new_df.context = con\n",
        "  new_df.question = que\n",
        "  new_df.ans_start = ans \n",
        "  new_df.text = txt \n",
        "  #removing duplicate columns \n",
        "  final_df = new_df.drop_duplicates(keep='first')\n",
        "\n",
        "  return final_df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVjCaABR1QbA"
      },
      "source": [
        "df=get_dataframe('/content/drive/MyDrive/Colab Notebooks/UNIV-AI-AI3/train-v2.0.json')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lILTaiexBCHh",
        "outputId": "ec302bd7-2aff-4cb9-c067-37f33736598d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>ans_start</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>269</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>207</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>526</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>166</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>276</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Id    title  ... ans_start                 text\n",
              "0  56be85543aeaaa14008c9063  Beyoncé  ...       269    in the late 1990s\n",
              "1  56be85543aeaaa14008c9065  Beyoncé  ...       207  singing and dancing\n",
              "2  56be85543aeaaa14008c9066  Beyoncé  ...       526                 2003\n",
              "3  56bf6b0f3aeaaa14008c9601  Beyoncé  ...       166       Houston, Texas\n",
              "4  56bf6b0f3aeaaa14008c9602  Beyoncé  ...       276           late 1990s\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg2GLiuNQ6-o"
      },
      "source": [
        "text=''.join(df.context.unique())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diLgwcQPUcMR"
      },
      "source": [
        "alphabets= \"([A-Za-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](com|net|org|io|gov)\"\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    text = \" \" + text + \"  \"\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
        "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
        "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
        "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<prd>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = sentences[:-1]\n",
        "    sentences = [s.strip() for s in sentences]\n",
        "    return sentences"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHxhlie2Vl68",
        "outputId": "c5488a2f-287d-4a1f-d69e-ac81d64ef54e"
      },
      "source": [
        "\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLEbvGPeVwVj"
      },
      "source": [
        "list_of_sentence=tokenizer.tokenize(text)\n",
        "list_of_sentence=[\"<s> \"+i+\" <'s>\" for i in list_of_sentence]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HfTBSgMNZBL",
        "outputId": "44f9e328-6018-4d90-eee7-dc073b47301e"
      },
      "source": [
        "list_of_sentence[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<s> Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. <'s>\",\n",
              " \"<s> Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. <'s>\",\n",
              " \"<s> Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. <'s>\",\n",
              " '<s> Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".Following the disbandment of Destiny\\'s Child in June 2005, she released her second solo album, B\\'Day (2006), which contained hits \"Déjà Vu\", \"Irreplaceable\", and \"Beautiful Liar\". <\\'s>',\n",
              " \"<s> Beyoncé also ventured into acting, with a Golden Globe-nominated performance in Dreamgirls (2006), and starring roles in The Pink Panther (2006) and Obsessed (2009). <'s>\",\n",
              " '<s> Her marriage to rapper Jay Z and portrayal of Etta James in Cadillac Records (2008) influenced her third album, I Am... Sasha Fierce (2008), which saw the birth of her alter-ego Sasha Fierce and earned a record-setting six Grammy Awards in 2010, including Song of the Year for \"Single Ladies (Put a Ring on It)\". <\\'s>',\n",
              " \"<s> Beyoncé took a hiatus from music in 2010 and took over management of her career; her fourth album 4 (2011) was subsequently mellower in tone, exploring 1970s funk, 1980s pop, and 1990s soul. <'s>\",\n",
              " '<s> Her critically acclaimed fifth studio album, Beyoncé (2013), was distinguished from previous releases by its experimental production and exploration of darker themes.A self-described \"modern-day feminist\", Beyoncé creates songs that are often characterized by themes of love, relationships, and monogamy, as well as female sexuality and empowerment. <\\'s>',\n",
              " \"<s> On stage, her dynamic, highly choreographed performances have led to critics hailing her as one of the best entertainers in contemporary popular music. <'s>\",\n",
              " \"<s> Throughout a career spanning 19 years, she has sold over 118 million records as a solo artist, and a further 60 million with Destiny's Child, making her one of the best-selling music artists of all time. <'s>\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn8H52BlJaLf"
      },
      "source": [
        "vocab_size=5000\n",
        "tokenizer=tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size,lower=True,oov_token='UNK')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlkHuigrB18l"
      },
      "source": [
        "tokenizer.fit_on_texts(list_of_sentence)\n",
        "token_list = tokenizer.texts_to_sequences(list_of_sentence)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T32Qa4mLMjyY"
      },
      "source": [
        "cleaned_list=[]\n",
        "for i in token_list:\n",
        "  if len(i)>25 and len(i)<251:\n",
        "    cleaned_list.append(i)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VidQ94nPb6TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3056aae-4875-4c4f-b732-60a85ebda519"
      },
      "source": [
        "len(max(cleaned_list,key=len))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X3fbsgOSf-M",
        "outputId": "78088e3e-a2be-41e6-e834-37fd6a60fbc8"
      },
      "source": [
        "print(cleaned_list[:5])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4, 826, 6, 1439, 7, 1597, 1985, 263, 1252, 7, 249, 3645, 6, 1, 3405, 10, 9, 842, 6, 1903, 8, 3520, 7, 2, 209, 1102, 10, 903, 3335, 3, 827, 740, 1, 178, 1, 842, 5], [4, 33, 1, 578, 2, 877, 3, 1, 3851, 658, 1, 7, 1678, 1008, 23, 213, 125, 10, 9, 3646, 1888, 1016, 3368, 258, 1, 1726, 6, 1635, 2, 2880, 1258, 408, 98, 38, 3439, 1, 7, 1678, 6, 1, 3647, 200, 2, 1, 3, 1, 842, 7, 362, 597, 263, 401, 125, 135, 3646, 658, 1, 476, 23, 2208, 3596, 1, 1, 1, 6, 4017, 1, 5], [4, 1576, 29, 1, 52, 3440, 16, 9, 2257, 4114, 4392, 929, 7, 1, 476, 6, 1, 2650, 7, 2, 1, 1, 476, 6, 1, 385, 5], [4, 125, 2293, 8, 1, 4850, 4271, 6, 1, 3, 1, 953, 7, 1, 518, 371, 885, 125, 287, 658, 119, 2223, 1, 1, 371, 23, 578, 2, 1548, 3, 125, 1, 1, 1, 1, 6, 3368, 9, 420, 2454, 513, 1, 1726, 7, 307, 78, 943, 3, 2, 95, 14, 308, 1, 913, 9, 1836, 17, 21, 5], [4, 1576, 313, 9, 1, 18, 127, 7, 307, 6, 313, 68, 1176, 3, 125, 2151, 125, 1145, 658, 176, 399, 12, 1440, 1, 7, 4328, 1, 1103, 1, 1057, 1864, 6, 1102, 2455, 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQC4XYBw1QQD"
      },
      "source": [
        "def get_dataset(token_list):\n",
        "  inp_token=[i[:-1] for i in token_list]\n",
        "  target_token=[i[1:] for i in token_list]\n",
        "  ragged_inp=tf.ragged.constant(inp_token)\n",
        "  ragged_target=tf.ragged.constant(target_token)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((ragged_inp,ragged_target))\n",
        "  dataset = dataset.batch(256)\n",
        "  dataset = dataset.map(lambda x,y: ((x.to_tensor(default_value=0, shape=[None, 234])), y.to_tensor(default_value=0, shape=[None, 234])), num_parallel_calls=5)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huwTY3vXNWuf"
      },
      "source": [
        "dataset=get_dataset(cleaned_list)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MLTf_D4NWl7"
      },
      "source": [
        "def create_model():\n",
        "  embed_dim=300\n",
        "  model=Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size+1,output_dim=300,mask_zero=True))\n",
        "  model.add(LSTM(units=512,return_sequences=True))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(LSTM(units=512,return_sequences=True))\n",
        "  model.add(Dropout(rate=0.1))\n",
        "  model.add(Dense(units=vocab_size+1,activation='softmax'))\n",
        "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
        "  return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jIQb0huctG9",
        "outputId": "57507e6b-b7ae-45b1-b865-1ad2224b5188"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model = create_model()\n",
        "else:\n",
        "    model = create_model()\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.55.163.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.55.163.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.55.163.74:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.55.163.74:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "YtVmAVdFR65x",
        "outputId": "2c93714d-4b8b-477b-ce4c-00ee54749c28"
      },
      "source": [
        "model.fit(dataset,epochs=10,verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "161/161 [==============================] - 158s 928ms/step - loss: 1.1061 - accuracy: 0.1511\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 150s 930ms/step - loss: 1.0459 - accuracy: 0.1719\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 148s 919ms/step - loss: 0.9944 - accuracy: 0.1939\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 149s 925ms/step - loss: 0.9682 - accuracy: 0.2090\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 148s 920ms/step - loss: 0.9517 - accuracy: 0.2134\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 149s 925ms/step - loss: 0.9380 - accuracy: 0.2177\n",
            "Epoch 7/10\n",
            " 30/161 [====>.........................] - ETA: 2:01 - loss: 0.9772 - accuracy: 0.2165"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7502e0ac2ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU5qC_b8PMvy",
        "outputId": "0fe69ef4-e185-4fe2-884f-9ec764f8c45d"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, None), (None, None)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1UYBrW1Qls2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}